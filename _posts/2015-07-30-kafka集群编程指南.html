<!DOCTYPE html><html><head><title>kafka集群编程指南</title><meta charset='utf-8'><link href='https://dn-maxiang.qbox.me/res-min/themes/marxico.css' rel='stylesheet'></head><body><div id='preview-contents' class='note-content'>
                        <div id="wmd-preview" class="preview-content"></div>
                    <div id="wmd-preview-section-22" class="wmd-preview-section preview-content">

</div><div id="wmd-preview-section-23" class="wmd-preview-section preview-content">

<h1 id="kafka集群编程指南">kafka集群编程指南</h1>

<p></p>

<div><div class="toc"><div class="toc">
<ul>
<li><a href="#kafka集群编程指南">kafka集群编程指南</a></li>
<li><a href="#一概述">一、概述</a><ul>
<li><a href="#一主要内容">（一）主要内容</a></li>
<li><a href="#二关于scala与java的说明">（二）关于scala与java的说明</a></li>
</ul>
</li>
<li><a href="#二producer的api">二、producer的API</a><ul>
<li><a href="#一scala版本deprecated">（一）scala版本（deprecated）</a></li>
<li><a href="#二java版本">（二）java版本</a></li>
</ul>
</li>
<li><a href="#三consumer的api">三、consumer的API</a><ul>
<li><a href="#一high-level-consummer">（一）high level consummer</a></li>
<li><a href="#二simplelow-level-consumer">（二）simple（low level) consumer</a></li>
</ul>
</li>
<li><a href="#四使用storm从kafka集群中消费消息">四、使用storm从kafka集群中消费消息</a></li>
<li><a href="#五使用spark-streaming从kafka集群中消费消息">五、使用spark streaming从kafka集群中消费消息</a></li>
<li><a href="#六与hadoop的集成">六、与hadoop的集成</a></li>
</ul>
</div>
</div>
</div>

<p>JAVA API：<a href="http://kafka.apache.org/082/javadoc/index.html" target="_blank">http://kafka.apache.org/082/javadoc/index.html</a></p>

</div><div id="wmd-preview-section-24" class="wmd-preview-section preview-content">

<h1 id="一概述">一、概述</h1>

</div><div id="wmd-preview-section-25" class="wmd-preview-section preview-content">

<h2 id="一主要内容">（一）主要内容</h2>

<p>本文主要介绍了以下4部分内容 <br>
（1）向kafka集群发送消息的producer JAVA API <br>
（2）从kafka集群消费消息的consumer JAVA API <br>
（3）使用storm从kafka集群中消费消息 <br>
（4）使用spark streaming从kafka集群中消费消息</p>

</div><div id="wmd-preview-section-26" class="wmd-preview-section preview-content">

<h2 id="二关于scala与java的说明">（二）关于scala与java的说明</h2>

<p>由于kafka本身是用scala语言写的，但大多使用kafka集群的用户都习惯使用java语言，因此，kafka使用scala语言写了一个java版本的API，目前它同时支持producer与consumer。 <br>
从0.8.2版本开始，kafka使用java语言重写了producer API，并计划于0.8.3（官方说下一个版本，没有具体说哪个）使用java语言重写consumer API。官方推荐使用新producer API代替原有的scala语言写的API。 <br>
总结： <br>
（1）kafka_0.8.2有2个版本producer API，分别是scala版本与java版本，前者放到源码的core目录下，后者放在源码的client目录下。官方推荐使用java语言版本，scala语言版本不再更新。 <br>
（2）kafka_0.8.2目前只有scala版本的consumer API，计划于下一个版本中增加java版本的。</p>

</div><div id="wmd-preview-section-27" class="wmd-preview-section preview-content">

<h1 id="二producer的api">二、producer的API</h1>

<p>此部分先简单介绍一下scala版本的API，然后再深入介绍java版本的API。</p>

</div><div id="wmd-preview-section-28" class="wmd-preview-section preview-content">

<h2 id="一scala版本deprecated">（一）scala版本（deprecated）</h2>

<p>基本步骤为创建producer——&gt;使用producer发送消息——&gt;关闭producer <br>
（1）创建producer</p>

</div><div id="wmd-preview-section-49" class="wmd-preview-section preview-content">

<pre class="prettyprint hljs-dark"><code class="hljs lasso">Properties props <span class="hljs-subst">=</span> <span class="hljs-literal">new</span> Properties();
props<span class="hljs-built_in">.</span>put(<span class="hljs-string">"serializer.class"</span>, <span class="hljs-string">"kafka.serializer.StringEncoder"</span>);
props<span class="hljs-built_in">.</span>put(<span class="hljs-string">"metadata.broker.list"</span>,<span class="hljs-string">"192.168.172.117:9092"</span>);
props<span class="hljs-built_in">.</span>put(<span class="hljs-string">"producer.type"</span>, <span class="hljs-string">"sync"</span>);
Producer<span class="hljs-subst">&lt;</span><span class="hljs-built_in">Integer</span>, <span class="hljs-built_in">String</span><span class="hljs-subst">&gt;</span> producer <span class="hljs-subst">=</span> <span class="hljs-literal">new</span> Producer<span class="hljs-subst">&lt;</span><span class="hljs-built_in">Integer</span>, <span class="hljs-built_in">String</span><span class="hljs-subst">&gt;</span>(<span class="hljs-literal">new</span> ProducerConfig(props));</code></pre>

<p>（2）使用producer发送消息 <br>
producer.send(new KeyedMessage&lt;Integer, String&gt;(“topic”, “message”); <br>
2个参数分别为topic名称和发送的消息内容，均为String类型。 <br>
（3）关闭producer <br>
producer.close();</p></div><div id="wmd-preview-section-30" class="wmd-preview-section preview-content">

<h2 id="二java版本">（二）java版本</h2>

<p>待补充</p>

</div><div id="wmd-preview-section-31" class="wmd-preview-section preview-content">

<h1 id="三consumer的api">三、consumer的API</h1>

<p>待补充</p>

</div><div id="wmd-preview-section-32" class="wmd-preview-section preview-content">

<h2 id="一high-level-consummer">（一）high level consummer</h2>

<p>提供了更高层的抽象, 详细请参考：<a href="https://cwiki.apache.org/confluence/display/KAFKA/Consumer+Group+Example" target="_blank">https://cwiki.apache.org/confluence/display/KAFKA/Consumer+Group+Example</a></p>

</div><div id="wmd-preview-section-33" class="wmd-preview-section preview-content">

<h2 id="二simplelow-level-consumer">（二）simple（low level) consumer</h2>

<p>对于大部分的应用来说，high level的api已经足够完成功能。如果需要更底层的功能（如定义启动时的offset等），则需要使用simple（low level) consumer。 <br>
详细请参考：<a href="https://cwiki.apache.org/confluence/display/KAFKA/0.8.0+SimpleConsumer+Example" target="_blank">https://cwiki.apache.org/confluence/display/KAFKA/0.8.0+SimpleConsumer+Example</a> <br>
For most applications, the high level consumer Api is good enough. Some applications want features not exposed to the high level consumer yet (e.g., set initial offset when restarting the consumer). They can instead use our low level SimpleConsumer Api. The logic will be a bit more complicated and you can follow the example in here. </p>

</div><div id="wmd-preview-section-34" class="wmd-preview-section preview-content">

<h1 id="四使用storm从kafka集群中消费消息">四、使用storm从kafka集群中消费消息</h1>

<p>一个简单示例： <br>
Core Spout</p>

</div><div id="wmd-preview-section-35" class="wmd-preview-section preview-content">

<pre class="prettyprint hljs-dark"><code class="hljs ocaml"><span class="hljs-type">BrokerHosts</span> hosts = <span class="hljs-keyword">new</span> <span class="hljs-type">ZkHosts</span>(zkConnString);
<span class="hljs-type">SpoutConfig</span> spoutConfig = <span class="hljs-keyword">new</span> <span class="hljs-type">SpoutConfig</span>(hosts, topicName, <span class="hljs-string">"/"</span> + topicName, <span class="hljs-type">UUID</span>.randomUUID<span class="hljs-literal">()</span>.toString<span class="hljs-literal">()</span>);
spoutConfig.scheme = <span class="hljs-keyword">new</span> <span class="hljs-type">SchemeAsMultiScheme</span>(<span class="hljs-keyword">new</span> <span class="hljs-type">StringScheme</span><span class="hljs-literal">()</span>);
<span class="hljs-type">KafkaSpout</span> kafkaSpout = <span class="hljs-keyword">new</span> <span class="hljs-type">KafkaSpout</span>(spoutConfig);</code></pre>

<p>Trident Spout</p>

</div><div id="wmd-preview-section-36" class="wmd-preview-section preview-content">

<pre class="prettyprint hljs-dark"><code class="hljs ocaml"><span class="hljs-type">TridentTopology</span> topology = <span class="hljs-keyword">new</span> <span class="hljs-type">TridentTopology</span><span class="hljs-literal">()</span>;
<span class="hljs-type">BrokerHosts</span> zk = <span class="hljs-keyword">new</span> <span class="hljs-type">ZkHosts</span>(<span class="hljs-string">"localhost"</span>);
<span class="hljs-type">TridentKafkaConfig</span> spoutConf = <span class="hljs-keyword">new</span> <span class="hljs-type">TridentKafkaConfig</span>(zk, <span class="hljs-string">"test-topic"</span>);
spoutConf.scheme = <span class="hljs-keyword">new</span> <span class="hljs-type">SchemeAsMultiScheme</span>(<span class="hljs-keyword">new</span> <span class="hljs-type">StringScheme</span><span class="hljs-literal">()</span>);
<span class="hljs-type">OpaqueTridentKafkaSpout</span> spout = <span class="hljs-keyword">new</span> <span class="hljs-type">OpaqueTridentKafkaSpout</span>(spoutConf);</code></pre>

<p>详细请参考storm-kafka编程指南</p>

</div><div id="wmd-preview-section-37" class="wmd-preview-section preview-content">

<h1 id="五使用spark-streaming从kafka集群中消费消息">五、使用spark streaming从kafka集群中消费消息</h1>

<p>1、定义你所需要完成的功能 <br>
这里以日志的过滤为例：</p>

</div><div id="wmd-preview-section-38" class="wmd-preview-section preview-content">

<pre class="prettyprint hljs-dark"><code class="hljs vbnet"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> FiltersFuntion <span class="hljs-keyword">implements</span> <span class="hljs-keyword">Function</span>&lt;Tuple2&lt;<span class="hljs-built_in">String</span>, <span class="hljs-built_in">String</span>&gt;, <span class="hljs-built_in">String</span>&gt;,akka.japi.<span class="hljs-keyword">Function</span>&lt;Tuple2&lt;<span class="hljs-built_in">String</span>, <span class="hljs-built_in">String</span>&gt;, <span class="hljs-built_in">String</span>&gt;</code></pre>

<p>关键是覆盖Function中的call()方法，它定义了对每一个消息所作的处理</p>

</div><div id="wmd-preview-section-39" class="wmd-preview-section preview-content">

<pre class="prettyprint hljs-dark"><code class="hljs delphi">@<span class="hljs-keyword">Override</span>
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">String</span> call(Tuple2&lt;<span class="hljs-keyword">String</span>, <span class="hljs-keyword">String</span>&gt; v1) throws Exception <span class="hljs-comment">{</span></code></pre>

<p>2、定义应用的结构</p>

</div><div id="wmd-preview-section-40" class="wmd-preview-section preview-content">

<pre class="prettyprint hljs-dark"><code class="hljs processing"><span class="hljs-keyword">public</span> <span class="hljs-keyword">final</span> class JavaKafkaWordCount {
  <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> Pattern SPACE = Pattern.compile(<span class="hljs-string">" "</span>);

  <span class="hljs-keyword">private</span> JavaKafkaWordCount() {
  }

  <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> main(<span class="hljs-keyword">String</span>[] args) {
    <span class="hljs-keyword">if</span> (args.length &lt; <span class="hljs-number">4</span>) {
      System.err.<span class="hljs-built_in">println</span>(<span class="hljs-string">"Usage: JavaKafkaWordCount &lt;zkQuorum&gt; &lt;group&gt; &lt;topics&gt; &lt;numThreads&gt;"</span>);
      System.<span class="hljs-built_in">exit</span>(<span class="hljs-number">1</span>);
    }

    SparkConf sparkConf = <span class="hljs-keyword">new</span> SparkConf().setAppName(<span class="hljs-string">"ljh_JavaKafkaWordCount"</span>);
    <span class="hljs-comment">// Create the context with a 1 second batch size</span>
    JavaStreamingContext jssc = <span class="hljs-keyword">new</span> JavaStreamingContext(sparkConf, <span class="hljs-keyword">new</span> Duration(<span class="hljs-number">2000</span>));

    <span class="hljs-built_in">int</span> numThreads = Integer.parseInt(args[<span class="hljs-number">3</span>]);
    Map&lt;<span class="hljs-keyword">String</span>, Integer&gt; topicMap = <span class="hljs-keyword">new</span> <span class="hljs-keyword">HashMap</span>&lt;<span class="hljs-keyword">String</span>, Integer&gt;();
    <span class="hljs-keyword">String</span>[] topics = args[<span class="hljs-number">2</span>].<span class="hljs-built_in">split</span>(<span class="hljs-string">","</span>);
    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">String</span> topic: topics) {
      topicMap.put(topic, numThreads);
    }

    JavaPairReceiverInputDStream&lt;<span class="hljs-keyword">String</span>, <span class="hljs-keyword">String</span>&gt; messages =
            KafkaUtils.createStream(jssc, args[<span class="hljs-number">0</span>], args[<span class="hljs-number">1</span>], topicMap);

    JavaDStream&lt;<span class="hljs-keyword">String</span>&gt; lines = messages.<span class="hljs-built_in">map</span>(<span class="hljs-keyword">new</span> FiltersFuntion() );

    JavaDStream&lt;<span class="hljs-keyword">String</span>&gt; words = lines.flatMap(<span class="hljs-keyword">new</span> FlatMapFunction&lt;<span class="hljs-keyword">String</span>, <span class="hljs-keyword">String</span>&gt;() {
      @Override
      <span class="hljs-keyword">public</span> Iterable&lt;<span class="hljs-keyword">String</span>&gt; call(<span class="hljs-keyword">String</span> x) {
        <span class="hljs-keyword">return</span> Lists.newArrayList(SPACE.<span class="hljs-built_in">split</span>(x));
      }
    });

    JavaPairDStream&lt;<span class="hljs-keyword">String</span>, Integer&gt; wordCounts = words.mapToPair(
      <span class="hljs-keyword">new</span> PairFunction&lt;<span class="hljs-keyword">String</span>, <span class="hljs-keyword">String</span>, Integer&gt;() {
        @Override
        <span class="hljs-keyword">public</span> Tuple2&lt;<span class="hljs-keyword">String</span>, Integer&gt; call(<span class="hljs-keyword">String</span> s) {
          <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> Tuple2&lt;<span class="hljs-keyword">String</span>, Integer&gt;(s, <span class="hljs-number">1</span>);
        }
      }).reduceByKey(<span class="hljs-keyword">new</span> Function2&lt;Integer, Integer, Integer&gt;() {
        @Override
        <span class="hljs-keyword">public</span> Integer call(Integer i1, Integer i2) {
          <span class="hljs-keyword">return</span> i1 + i2;
        }
      });

    wordCounts.<span class="hljs-built_in">print</span>();
    jssc.start();
    jssc.awaitTermination();
  }
}</code></pre>

</div><div id="wmd-preview-section-41" class="wmd-preview-section preview-content">

<h1 id="六与hadoop的集成">六、与hadoop的集成</h1>

<p>通过一个叫camus的第三方项目实现，请谨慎使用。 <br>
Providing a horizontally scalable solution for aggregating and loading data into Hadoop was one of our basic use cases. To support this use case, we provide a Hadoop-based consumer which spawns off many map tasks to pull data from the Kafka cluster in parallel. This provides extremely fast pull-based Hadoop data load capabilities (we were able to fully saturate the network with only a handful of Kafka servers). </p>

<p>详细请参考项目：<a href="https://github.com/linkedin/camus/" target="_blank">https://github.com/linkedin/camus/</a></p></div><div id="wmd-preview-section-footnotes" class="preview-content"></div></div></body></html>w-content"></div></div></body></html>