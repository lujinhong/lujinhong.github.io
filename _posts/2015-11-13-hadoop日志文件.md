---
layout: post
tile:  "hadoop日志文件"
date:  2015-11-13 15:00:42
categories: hadoop 
excerpt: hadoop日志文件
---

* content
{:toc}



[TOC]

hadoop存在多种日志文件，其中master上的日志文件记录全面信息，包括slave上的jobtracker与datanode也会将错误信息写到master中。而slave中的日志主要记录完成的task任务信息。

默认情况下，hadoop日志保存在HADOOP_INSTALL/logs目录，但一般情况下建议重新指定路径，常用的是/var/log/hadoop，通过在hadoop-env.sh中增加以下一行来实现：
export HADOOP_LOG_DIR=/var/log/hadoop


##一、master服务器上的日志

1、保存在master服务器上的日志有以下四类。注意，tasktracker与datanode上的部分日志会保存在master中，方便出现问题时定位至具体服务器。

2、master中主要有2种日志，分别以log与out作后缀，其中每一个守护进程都会产生这2个日志，如jobtracker/ namenode/ tasktracker/ datanode均会分别产生这2个日志文件。这2个文件均是每天生成一个。

3、log日志文件通过log4j记录的，大部分应用程序的日志消息都写到该日志文件中，故障诊断的首要步骤即为检查该文件。【此日志文件最重要】
out日志文件记录标准输出和标准错误日志，由于大多日志均使用log4j输出至log日志文件中，因此此文件很小或者为空。系统仅保留最新的5个日志。

4、这2类日志的命名均包含用户名称、守护进程名称和本地主机名等信息。


##二、slave服务器上的日志

（一）tasktracker相关日志
每个tasktracker子进程都用log4j产生以下4个日志文件，这些日志记录了各个task的日志输出。
1、日志文件(syslog)
通过Log4j记录的日志

2、保存发到标准输出数据的文件(stdout)

3、保存标准错误的文件(stderr)

4、log.index

（1）tasktracker会记录它所运行的所有task的日志，默认目录为$HADOOP_LOG_DIR/userlogs。且每个job单独生成一个目录，如下：
	
	[jediael@slave1 userlogs]$ pwd
	/mnt/jediael/hadoop-1.2.1/logs/userlogs
	jediael@slave1 userlogs]$ ls
	job_201502271057_0243  job_201502271057_0245  job_201502271057_0247  job_201502271057_0250  job_201502271057_0253
	job_201502271057_0244  job_201502271057_0246  job_201502271057_0249  job_201502271057_0251  job_201502271057_0255	

（2）进入具体目录，内容如下
	
	[jediael@slave1 job_201502271057_0243]$ ll
	total 16
	lrwxrwxrwx 1 jediael jediael  95 Feb 28 15:06 attempt_201502271057_0243_m_000000_0 -> /mnt/tmphadoop/mapred/local/userlogs/job_201502271057_0243/attempt_201502271057_0243_m_000000_0
	lrwxrwxrwx 1 jediael jediael  95 Feb 28 15:06 attempt_201502271057_0243_m_000001_0 -> /mnt/tmphadoop/mapred/local/userlogs/job_201502271057_0243/attempt_201502271057_0243_m_000001_0
	lrwxrwxrwx 1 jediael jediael  95 Feb 28 15:06 attempt_201502271057_0243_m_000002_0 -> /mnt/tmphadoop/mapred/local/userlogs/job_201502271057_0243/attempt_201502271057_0243_m_000002_0
	-rw-r----- 1 jediael jediael 502 Feb 28 15:06 job-acls.xml
由此可见，这个tasktracker运行了3个job_201502271057_0243的task，这个task的日志目录只是一个链接，它具体链接至tmphadoop目录下。

（3）进入实际目录，可以发现以下4个日志文件
	
	[jediael@slave1 userlogs]$ cd /mnt/tmphadoop/mapred/local/userlogs/job_201502271057_0243/attempt_201502271057_0243_m_000000_0
	[jediael@slave1 attempt_201502271057_0243_m_000000_0]$ ll
	total 36
	-rw-r--r-- 1 jediael jediael   154 Feb 28 15:06 log.index
	-rw-rw-r-- 1 jediael jediael     0 Feb 28 15:06 stderr
	-rw-rw-r-- 1 jediael jediael     0 Feb 28 15:06 stdout
	-rw-rw-r-- 1 jediael jediael 30248 Feb 28 15:06 syslog

（二）datanode相关日志

##三、审计日志
这个日志记录所有HDFS请求，默认是关闭的。一般写入namenode的日志中
在log4j.properties属性文件中设置以下选项：
	
	# All audit events are logged at INFO level
	log4j.logger.org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit=WARN
由于审计信息在INFO级别实现的，因此将WARN改为info即可开启审计。

##四、MR作业历史日志
记录已经完成的任务，放在HADOOP_LOG_DIR/histroy中。
