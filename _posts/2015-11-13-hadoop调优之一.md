---
layout: post
tile:  "hadoop调优之一"
date:  2015-11-13 14:58:06
categories: hadoop 
excerpt: hadoop调优之一
---

* content
{:toc}




[TOC]
#一、概述
hadoop集群性能低下的常见原因

##（一）硬件环境
1、CPU/内存不足，或未充分利用
2、网络原因
3、磁盘原因

##（二）map任务原因

1、输入文件中小文件过多，导致多次启动和停止JVM进程。可以设置JVM重用。

2、数据倾斜：大文件且不可分割，导致处理这些文件的map需要很长时间。

3、数据本地化效果差。

##（三）reduce任务的原因
1、reduce任务数量过大或过小
2、数据倾斜：一部分key的记录数量太大，导致某些reduce执行过慢
3、缓慢的shuffle和排序

##（四）hadoop的配置不当

##（五）JAVA代码及JVM调优



#一、硬件调优

##1、CPU/内存使用情况vmstat、top

	$ vmstat -S M 5
	
	procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu-----
	
	 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
	
	 0  0      0    566    232    239    0    0    65   824   59   39  4  1 93  1  0
	
	 0  3      0    366    232    432    0    0     0 25929 2638 2776 14 14 43 28  0
	
	 2  1      0    241    232    543    0    0    26 38110 2123 1316 75 11  0 14  0
	
	 3  0      0     78    232    543    0    0     0 11784 1558 1028 80  4 16  0  0
	
	 0  0      0    189    232    543    0    0     0   142 1052  933 70  3 27  1  0
	
	 0  0      0    185    232    543    0    0     0    30  500  589 15  1 84  0  0
	
	 2  0      0    180    232    544    0    0     0     3  502  595 12  1 87  0  0
	
	 0  0      0    508    232    293    0    0     0    74 1161 1036 77  5 18  0  0
	
	 0  0      0    626    233    175    0    0     0   150  385  447  2  1 97  0  0



以上各个字段的意思分别是：

好了，命令介绍完毕，现在开始实战讲解每个参数的意思。

r 表示运行队列(就是说多少个进程真的分配到CPU)，当这个值超过了CPU数目，就会出现CPU瓶颈 了。这个也和top的负载有关系，一般负载超过了3就比较高，超过了5就高，超过了10就不正常了，服务器的状态很危险。top的负载类似每秒的运行队 列。如果运行队列过大，表示你的CPU很繁忙，一般会造成CPU使用率很高。

b 表示阻塞的进程,这个不多说，进程阻塞，大家懂的。

swpd 虚拟内存已使用的大小，如果大于0，表示你的机器物理内存不足了，如果不是程序内存泄露的原因，那么你该升级内存了或者把耗内存的任务迁移到其他机器。

free   空闲的物理内存的大小，我的机器内存总共8G，剩余3415M。

buff   Linux/Unix系统是用来存储，目录里面有什么内容，权限等的缓存，我本机大概占用300多M

cache cache直接用来记忆我们打开的文件,给文件做缓冲，我本机大概占用300多M(这里是Linux/Unix的聪明之处，把空闲的物理内存的一部分拿来做文件和目录的缓存，是为了提高 程序执行的性能，当程序使用内存时，buffer/cached会很快地被使用。)

si  每秒从磁盘读入虚拟内存的大小，如果这个值大于0，表示物理内存不够用或者内存泄露了，要查找耗内存进程解决掉。我的机器内存充裕，一切正常。

so  每秒虚拟内存写入磁盘的大小，如果这个值大于0，同上。

bi  块设备每秒接收的块数量，这里的块设备是指系统上所有的磁盘和其他块设备，默认块大小是1024byte，我本机上没什么IO操作，所以一直是0，但是我曾在处理拷贝大量数据(2-3T)的机器上看过可以达到140000/s，磁盘写入速度差不多140M每秒

bo 块设备每秒发送的块数量，例如我们读取文件，bo就要大于0。bi和bo一般都要接近0，不然就是IO过于频繁，需要调整。

in 每秒CPU的中断次数，包括时间中断

cs 每秒上下文切换次数，例如我们调用系统函数，就要进行上下文切换，线程的切换，也要进程上下文切换，这个值要越小越好，太大了，要考虑调低线程或者进程的 数目,例如在apache和nginx这种web服务器中，我们一般做性能测试时会进行几千并发甚至几万并发的测试，选择web服务器的进程可以由进程或 者线程的峰值一直下调，压测，直到cs到一个比较小的值，这个进程和线程数就是比较合适的值了。系统调用也是，每次调用系统函数，我们的代码就会进入内核 空间，导致上下文切换，这个是很耗资源，也要尽量避免频繁调用系统函数。上下文切换次数过多表示你的CPU大部分浪费在上下文切换，导致CPU干正经事的 时间少了，CPU没有充分利用，是不可取的。

us 用户CPU时间，我曾经在一个做加密解密很频繁的服务器上，可以看到us接近100,r运行队列达到80(机器在做压力测试，性能表现不佳)。

sy 系统CPU时间，如果太高，表示系统调用时间长，例如是IO操作频繁。

id  空闲 CPU时间，一般来说，id + us + sy = 100,一般我认为id是空闲CPU使用率，us是用户CPU使用率，sy是系统CPU使用率。


wt 等待IO CPU时间。

##2、网络

（1）ethtool：检查网卡是否工作正常，是否全双工，速度设置是否合理等。


（2）sar：比较各个网卡的性能
	
	
	# sar -n DEV 3 2
	
	Linux 2.6.32-431.23.3.el6.x86_64 (slave1)       03/13/2015      _x86_64_        (1 CPU)
	
	08:41:11 PM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s
	
	08:41:14 PM        lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00
	
	08:41:14 PM      eth0     11.71     10.70      1.05      4.47      0.00      0.00      0.00
	
	08:41:14 PM      eth1    144.48      0.00      5.93      0.00      0.00      0.00      0.00
	
	08:41:14 PM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s
	
	08:41:17 PM        lo     28.04     28.04      3.90      3.90      0.00      0.00      0.00
	
	08:41:17 PM      eth0    183.45   3765.20     27.06    905.80      0.00      0.00      0.00
	
	08:41:17 PM      eth1    179.05     31.76      7.48     70.62      0.00      0.00      0.00
	
	Average:        IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s
	
	Average:           lo     13.95     13.95      1.94      1.94      0.00      0.00      0.00
	
	Average:         eth0     97.14   1878.49     13.99    452.86      0.00      0.00      0.00
	
	Average:         eth1    161.68     15.80      6.70     35.13      0.00      0.00      0.00



（3）iperf：检查2台机器间的网络带宽

其中一台充当服务器：

	# iperf -s
	
	------------------------------------------------------------
	
	Server listening on TCP port 5001
	
	TCP window size: 85.3 KByte (default)
	
	------------------------------------------------------------
	
	[  4] local 10.171.94.155 port 5001 connected with 10.171.29.191 port 46455
	
	------------------------------------------------------------
	
	Client connecting to 10.171.29.191, TCP port 5001
	
	TCP window size:  143 KByte (default)
	
	------------------------------------------------------------
	
	[  6] local 10.171.94.155 port 52215 connected with 10.171.29.191 port 5001
	
	[ ID] Interval       Transfer     Bandwidth
	
	[  6]  0.0-10.0 sec   664 MBytes   557 Mbits/sec
	
	[  4]  0.0-10.0 sec   466 MBytes   390 Mbits/sec
	
	
	
	另一台充当客户端：
	
	# iperf -c 10.171.94.155 -f m -d
	
	------------------------------------------------------------
	
	Server listening on TCP port 5001
	
	TCP window size: 0.08 MByte (default)
	
	------------------------------------------------------------
	
	------------------------------------------------------------
	
	Client connecting to 10.171.94.155, TCP port 5001
	
	TCP window size: 0.10 MByte (default)
	
	------------------------------------------------------------
	
	[  4] local 10.171.29.191 port 46455 connected with 10.171.94.155 port 5001
	
	[  5] local 10.171.29.191 port 5001 connected with 10.171.94.155 port 52215
	
	[ ID] Interval       Transfer     Bandwidth
	
	[  4]  0.0-10.0 sec   466 MBytes   390 Mbits/sec
	
	[  5]  0.0-10.0 sec   664 MBytes   555 Mbits/sec



（4）tcpdump：检查数据包的传输情况

	# tcpdump port 8649
	
	tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
	
	listening on eth0, link-type EN10MB (Ethernet), capture size 65535 bytes
	
	20:43:11.396729 IP master.38498 > slave1.8649: UDP, length 136
	
	20:43:11.396746 IP master.38498 > slave1.8649: UDP, length 64
	
	20:43:11.397101 IP master.38498 > slave1.8649: UDP, length 136
	
	20:43:11.397105 IP master.38498 > slave1.8649: UDP, length 64
	
	20:43:11.397107 IP master.38498 > slave1.8649: UDP, length 136
	
	20:43:11.397108 IP master.38498 > slave1.8649: UDP, length 80
	
	20:43:11.397109 IP master.38498 > slave1.8649: UDP, length 64
	
	20:43:11.397110 IP master.38498 > slave1.8649: UDP, length 144
	
	20:43:11.397111 IP master.38498 > slave1.8649: UDP, length 68
	
	20:43:11.397112 IP master.38498 > slave1.8649: UDP, length 156
	
	20:43:11.397114 IP master.38498 > slave1.8649: UDP, length 188
	
	20:43:11.397115 IP master.38498 > slave1.8649: UDP, length 92
	
	20:43:11.397116 IP master.38498 > slave1.8649: UDP, length 88


还可以使用host等参数。

##3、磁盘健康情况

（1）iostart

	# iostat
	
	Linux 2.6.32-431.17.1.el6.x86_64 (master)       03/13/2015      _x86_64_        (1 CPU)
	
	avg-cpu:  %user   %nice %system %iowait  %steal   %idle
	
	           4.73    0.00    3.07   33.99    0.00   58.22
	
	Device:            tps   Blk_read/s   Blk_wrtn/s   Blk_read   Blk_wrtn
	
	xvda            206.31       292.48      2301.51  176511452 1388963336
	
	xvdb             10.24        69.64       645.59   42029194  389614304
	
	[root@master ~]# 
	
	[root@master ~]# 
	
	[root@master ~]# iostat -m -x -d 5
	
	Linux 2.6.32-431.17.1.el6.x86_64 (master)       03/13/2015      _x86_64_        (1 CPU)
	
	Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util
	
	xvda              0.16   115.94   34.57  171.74     0.14     1.12    12.57     4.92   23.83   1.87  38.49
	
	xvdb              0.00    71.55    1.09    9.14     0.03     0.32    69.88     0.89   87.38   0.89   0.91
	
	Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await  svctm  %util
	
	xvda              0.00     0.00    0.00    0.81     0.00     0.00     8.00     0.00    4.75   1.75   0.14
	
	xvdb              0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00   0.00   0.00



（2）dmesg

输出详细的错误信息，常见的信息如下：


	type=1400 audit(1425645012.364:7): avc:  denied  { setattr } for  pid=1318 comm="rrdtool" name="fontconfig" dev=xvda1 ino=1049117 scontext=unconfined_u:system_r:httpd_t:s0 tcontext=system_u:object_r:fonts_cache_t:s0 tclass=dir




#二、map端调优
1、输入文件中小文件过多，导致多次启动和停止JVM进程。

可以设置JVM重用。或者作数据预处理，将小文件合并。

2、数据倾斜：大文件且不可分割，导致处理这些文件的map需要很长时间。

尽量避免这种情况出现，可以通过预处理解决。

3、数据本地化效果差。

将数据均衡的分布到集群中：

start-balancer.sh

4、检查是否某天数据量突然暴增


#三、reduce端调优

1、不使用reduce
map结束后向reduce传输结果时需要经过shuffle阶段及排序，并通过网络传输数据，此过程引起较大的损耗，因此，在满足一定条件的情况下，可以将reduce任务设置为0。
job.setNumReduceTasks(0);
注意必须显示的定义数量为0，否则默认情况下，会有一个reduce任务，类为Reduce，此类将输入KV直接作为输出KV。

2、过滤和投影
如果一定要有reduce过程，那下一步就是尽量减少map输出的数据量，一方面可以减少网络传输数据，另一方面可以减少reduce需要处理的数据。
减少map的输出数据量有2种常见的方法：
（1）过滤：将对最终结果无影响的整个记录删除。
（2）投影：删除记录中某些对最终结果无影响的项。

3、使用combiner
使用combiners可以在map阶段通过合并数据，从而减少向reduce传输数据。

4、优化比较器
此方法可以提高数据排序顺序

5、减少倾斜数据
由于map的输出中某个key对应大量的value值，从而导致处理这个key的reduce任务所耗时间远远大于其它reduce。

6、reduce的数量调整
将reduce的数量调整为比集客reduce slot总数少一点，这可以保证充分利用集群的性能，又可容忍一定的机器错误。


#四、hadoop配置不当
充分了解hadoop的配置文件，为集群选择最佳配置。
参考：http://blog.csdn.net/jediael_lu/article/details/38680013

#五、java调优
参考：？？
